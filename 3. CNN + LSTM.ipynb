{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Renewable Energy Output Using Long-Short Term Memory and Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Science Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#TensorFlow packages required for building CNN + LSTM model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Input, Dense, Flatten, LSTM, Reshape, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#Plotting graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plotting Keras Model\n",
    "import keras.utils.vis_utils\n",
    "from importlib import reload\n",
    "reload(keras.utils.vis_utils)\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "#Utility Module for computing and displaying metrics\n",
    "from utility_functions import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data and split into Train, Test and Validation\n",
    "- Fetch the first 70% records as train and the rest 15% each as validation and test\n",
    "    - 8711 * 70% = 6097 records from the start (Train)\n",
    "    - 6097 + 1307 = 6098 to 7404 records as (Validation)\n",
    "    - 7404 + 1307 = 7405 to 8711 records as (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_dataset = pd.read_csv('data/final_thesis_dataset.csv',parse_dates=[0], index_col=0)\n",
    "\n",
    "#Extracting dataset into train, validation and test sets\n",
    "train = thesis_dataset[:6097]\n",
    "valid = thesis_dataset[6097:7404]\n",
    "test = thesis_dataset[7404:]\n",
    "\n",
    "#Extracting solar and wind X, y columns per set\n",
    "X_solar_train = train[['SWTDN', 'SWGDN', 'T', 'p']]\n",
    "y_solar_train = train['DE_solar_generation_actual']\n",
    "X_solar_valid = valid[['SWTDN', 'SWGDN', 'T', 'p']]\n",
    "y_solar_valid = valid['DE_solar_generation_actual']\n",
    "X_solar_test = test[['SWTDN', 'SWGDN', 'T', 'p']]\n",
    "y_solar_test = test['DE_solar_generation_actual']\n",
    "\n",
    "X_wind_train = train[['v1', 'v2', 'v_50m', 'z0']]\n",
    "y_wind_train = train['DE_wind_generation_actual']\n",
    "X_wind_valid = valid[['v1', 'v2', 'v_50m', 'z0']]\n",
    "y_wind_valid = valid['DE_wind_generation_actual']\n",
    "X_wind_test = test[['v1', 'v2', 'v_50m', 'z0']]\n",
    "y_wind_test = test['DE_wind_generation_actual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN + LSTM TensorFlow Model using Conv1D and LSTM for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input layer describing the dimension in which the data will be passed\n",
    "digit_a = Input(shape=(4,))\n",
    "#Reshape helps in converting row * col wise data into only col wise data for Conv layer to process\n",
    "x = Reshape((-1,1))(digit_a)\n",
    "#Building Conv layers of 128 filters and 2 kernel_size with BatchNormalization\n",
    "x = Conv1D(128, 2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(128, 2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(128, 2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "#Flattening the output into timedistributed fashion for LSTM to process\n",
    "out_a = TimeDistributed(Flatten())(x)\n",
    "\n",
    "#LSTM layer with 1024 units and with no return_sequences\n",
    "out = LSTM(1024, input_shape = train.shape, return_sequences=False)(out_a)\n",
    "#Dense layer of 1024 that captures the output of LSTM layer\n",
    "out = Dense(1024)(out)\n",
    "#BatchNormalization followed by Dense of 1 layer to get the output of the model\n",
    "out = BatchNormalization()(out)\n",
    "out = Dense(1)(out)\n",
    "#Create the layer and print the summary\n",
    "model = Model(digit_a, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model by passing adam optimizer, loss=MAE and fetching accuracy metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'mean_absolute_error', ['accuracy'])\n",
    "history = model.fit(X_solar_train, y_solar_train, validation_data=(X_solar_valid, y_solar_valid), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_solar_test, y_solar_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    model, to_file='figs/3-model.png', show_shapes=False, show_dtype=False,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Model's Accuracy and Loss Metrics over Train and Validation sets for Solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Actual vs Predictions on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_solar_pred = model.predict(X_solar_train)\n",
    "val_solar_pred = model.predict(X_solar_valid)\n",
    "test_solar_pred = model.predict(X_solar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = thesis_dataset[['DE_solar_generation_actual']]\n",
    "\n",
    "train_df = train[['DE_solar_generation_actual']]\n",
    "train_df.loc[:, 'DE_solar_generation_actual'] = train_solar_pred\n",
    "\n",
    "valid_df = valid[['DE_solar_generation_actual']]\n",
    "valid_df.loc[:, 'DE_solar_generation_actual'] = val_solar_pred\n",
    "\n",
    "test_df = test[['DE_solar_generation_actual']]\n",
    "test_df.loc[:, 'DE_solar_generation_actual'] = test_solar_pred\n",
    "\n",
    "# # Plot all predictions\n",
    "inversetransform, =plt.plot(df, label = 'Actual')\n",
    "train_solar_predx, =plt.plot(train_df, color='orange', label = 'Train')\n",
    "val_solar_predx, =plt.plot(valid_df, color='green', label = 'Validation')\n",
    "test_solar_predx, =plt.plot(test_df, color='black', label = 'Test')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Solar Output')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Predicted vs. Actual Solar Generation\")\n",
    "\n",
    "# plt.savefig('figs/3-solar.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics for Solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics('cnn+lstm', test[['DE_solar_generation_actual']], test_solar_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the same model for Wind Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'mean_absolute_error', ['accuracy'])\n",
    "history = model.fit(X_wind_train, y_wind_train, validation_data=(X_wind_valid, y_wind_valid), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_wind_test, y_wind_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's Accuracy and Loss for Wind Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Actual vs Predicted for Wind on same graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wind_pred = model.predict(X_wind_train)\n",
    "val_wind_pred = model.predict(X_wind_valid)\n",
    "test_wind_pred = model.predict(X_wind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = thesis_dataset[['DE_wind_generation_actual']]\n",
    "\n",
    "train_df = train[['DE_wind_generation_actual']]\n",
    "train_df.loc[:, 'DE_wind_generation_actual'] = train_wind_pred\n",
    "\n",
    "valid_df = valid[['DE_wind_generation_actual']]\n",
    "valid_df.loc[:, 'DE_wind_generation_actual'] = val_wind_pred\n",
    "\n",
    "test_df = test[['DE_wind_generation_actual']]\n",
    "test_df.loc[:, 'DE_wind_generation_actual'] = test_wind_pred\n",
    "\n",
    "# Plot all predictions\n",
    "inversetransform, =plt.plot(df, label = 'Actual')\n",
    "train_wind_predx, =plt.plot(train_df, color='orange', label = 'Train')\n",
    "val_wind_predx, =plt.plot(valid_df, color='green', label = 'Validation')\n",
    "test_wind_predx, =plt.plot(test_df, color='black', label = 'Test')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Wind Output')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Predicted vs. Actual Wind Generation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics for Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics('cnn+lstm', test[['DE_wind_generation_actual']], test_wind_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reason for this is because Wind Energy Production is highly random in nature.\n",
    "### So CNN + LSTM model couldn't map it as accurately as in Solar Energy Production scenario. So in order to resolve it we use another method - WD that decomposes this variability for our LSTM to predict well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
